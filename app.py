from flask import Flask, request, jsonify, abort
from flask_cors import CORS
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address
import akshare as ak
import pandas as pd
import requests
import re
import time
import os
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from functools import wraps
import numpy as np
from dotenv import load_dotenv
from concurrent.futures import ThreadPoolExecutor, as_completed

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = Flask(__name__)

# å®‰å…¨é…ç½®
app.config['JSON_AS_ASCII'] = False
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # é™åˆ¶è¯·æ±‚ä½“16MB

# CORSé…ç½®ï¼ˆç”Ÿäº§ç¯å¢ƒè¯·é™åˆ¶ä¸ºç‰¹å®šåŸŸåï¼‰
CORS(app, resources={
    r"/api/*": {
        "origins": "*",  # å¿…é¡»æ˜¯ *ï¼Œä¸èƒ½æ˜¯æ•°ç»„
        "methods": ["POST", "GET", "OPTIONS"],
        "allow_headers": ["Content-Type"],
        "supports_credentials": True
    }
})

# é€Ÿç‡é™åˆ¶é…ç½®
limiter = Limiter(
    app=app,
    key_func=get_remote_address,
    default_limits=["200 per day", "50 per hour"],
    storage_uri="memory://"
)

# ==========================================
# é€šç”¨AIæœåŠ¡é…ç½® - æ”¯æŒå¤šæä¾›å•†ï¼ˆä»…ç”¨äºè§£æåŸºé‡‘ï¼‰
# ==========================================

class AIProvider:
    """AIæä¾›å•†é…ç½®"""
    
    # æ”¯æŒçš„æä¾›å•†é…ç½®æ¨¡æ¿
    PROVIDERS = {
        'deepseek': {
            'api_url': 'https://api.deepseek.com/v1/chat/completions',
            'model': 'deepseek-chat',
            'auth_header': 'Authorization',
            'auth_prefix': 'Bearer ',
            'request_format': 'openai',  # è¯·æ±‚æ ¼å¼
            'response_path': 'choices.0.message.content',  # å“åº”æå–è·¯å¾„
        },
        'openai': {
            'api_url': 'https://api.openai.com/v1/chat/completions',
            'model': 'gpt-3.5-turbo',
            'auth_header': 'Authorization',
            'auth_prefix': 'Bearer ',
            'request_format': 'openai',
            'response_path': 'choices.0.message.content',
        },
        'azure_openai': {
            'api_url': '',  # éœ€è¦å¡«å†™ Azure Endpoint
            'model': 'gpt-35-turbo',
            'auth_header': 'api-key',
            'auth_prefix': '',
            'request_format': 'openai',
            'response_path': 'choices.0.message.content',
        },
        'anthropic': {
            'api_url': 'https://api.anthropic.com/v1/messages',
            'model': 'claude-3-sonnet-20240229',
            'auth_header': 'x-api-key',
            'auth_prefix': '',
            'request_format': 'anthropic',
            'response_path': 'content.0.text',
        },
        'gemini': {
            'api_url': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent',
            'model': 'gemini-pro',
            'auth_header': 'key',  # Geminiä½¿ç”¨URLå‚æ•°æˆ–header
            'auth_prefix': '',
            'request_format': 'gemini',
            'response_path': 'candidates.0.content.parts.0.text',
        },
        'ollama': {
            'api_url': 'http://localhost:11434/api/generate',
            'model': 'llama2',
            'auth_header': '',
            'auth_prefix': '',
            'request_format': 'ollama',
            'response_path': 'response',
        },
        'openai_compatible': {
            'api_url': '',  # è‡ªå®šä¹‰å…¼å®¹OpenAIçš„APIåœ°å€
            'model': '',    # è‡ªå®šä¹‰æ¨¡å‹å
            'auth_header': 'Authorization',
            'auth_prefix': 'Bearer ',
            'request_format': 'openai',
            'response_path': 'choices.0.message.content',
        }
    }
    
    def __init__(self):
        # è¯»å–ç¯å¢ƒå˜é‡é…ç½®
        self.provider = os.environ.get('AI_PROVIDER', 'deepseek').lower()
        self.api_key = os.environ.get('AI_API_KEY') or os.environ.get(f'{self.provider.upper()}_API_KEY')
        self.api_url = os.environ.get('AI_API_URL') or os.environ.get(f'{self.provider.upper()}_API_URL')
        self.model = os.environ.get('AI_MODEL')
        
        # è·å–æä¾›å•†é…ç½®
        self.config = self.PROVIDERS.get(self.provider, self.PROVIDERS['openai_compatible']).copy()
        
        # å¦‚æœç¯å¢ƒå˜é‡æœ‰è®¾ç½®ï¼Œè¦†ç›–é»˜è®¤å€¼
        if self.api_url:
            self.config['api_url'] = self.api_url
        if self.model:
            self.config['model'] = self.model
            
        # å‘åå…¼å®¹ï¼šå¦‚æœè®¾ç½®äº†æ—§çš„DEEPSEEKé…ç½®ï¼Œè‡ªåŠ¨ä½¿ç”¨
        if not self.api_key:
            deepseek_key = os.environ.get('DEEPSEEK_API_KEY')
            if deepseek_key:
                self.provider = 'deepseek'
                self.api_key = deepseek_key
                self.config = self.PROVIDERS['deepseek'].copy()
                deepseek_url = os.environ.get('DEEPSEEK_API_URL')
                if deepseek_url:
                    self.config['api_url'] = deepseek_url
    
    def is_configured(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å·²é…ç½®"""
        return bool(self.api_key and self.config.get('api_url'))
    
    def get_headers(self) -> dict:
        """è·å–è¯·æ±‚å¤´"""
        headers = {'Content-Type': 'application/json'}
        auth_header = self.config.get('auth_header')
        if auth_header and self.api_key:
            auth_prefix = self.config.get('auth_prefix', '')
            headers[auth_header] = f'{auth_prefix}{self.api_key}'
        return headers
    
    def build_request_body(self, prompt: str, temperature: float = 0.7, max_tokens: int = 2000) -> dict:
        """æ„å»ºè¯·æ±‚ä½“"""
        fmt = self.config.get('request_format', 'openai')
        model = self.config.get('model', 'gpt-3.5-turbo')
        
        if fmt == 'openai':
            return {
                'model': model,
                'messages': [{'role': 'user', 'content': prompt}],
                'temperature': temperature,
                'max_tokens': max_tokens
            }
        elif fmt == 'anthropic':
            return {
                'model': model,
                'messages': [{'role': 'user', 'content': prompt}],
                'max_tokens': max_tokens,
                'temperature': temperature
            }
        elif fmt == 'gemini':
            return {
                'contents': [{
                    'parts': [{'text': prompt}]
                }],
                'generationConfig': {
                    'temperature': temperature,
                    'maxOutputTokens': max_tokens
                }
            }
        elif fmt == 'ollama':
            return {
                'model': model,
                'prompt': prompt,
                'stream': False,
                'options': {
                    'temperature': temperature
                }
            }
        else:
            # é»˜è®¤ä½¿ç”¨ OpenAI æ ¼å¼
            return {
                'model': model,
                'messages': [{'role': 'user', 'content': prompt}],
                'temperature': temperature,
                'max_tokens': max_tokens
            }
    
    def extract_response(self, data: dict) -> str:
        """ä»å“åº”ä¸­æå–å†…å®¹"""
        path = self.config.get('response_path', 'choices.0.message.content')
        keys = path.split('.')
        
        try:
            value = data
            for key in keys:
                if key.isdigit():
                    value = value[int(key)]
                else:
                    value = value[key]
            return str(value) if value else ""
        except (KeyError, IndexError, TypeError) as e:
            logger.error(f"æ— æ³•ä»å“åº”ä¸­æå–å†…å®¹: {e}, path={path}, data={json.dumps(data)[:500]}")
            return ""
    
    def chat(self, prompt: str, temperature: float = 0.7, max_tokens: int = 2000, timeout: int = 60) -> str:
        """å‘é€èŠå¤©è¯·æ±‚"""
        if not self.is_configured():
            raise ValueError(f"AIæä¾›å•† '{self.provider}' æœªé…ç½®")
        
        url = self.config.get('api_url')
        headers = self.get_headers()
        body = self.build_request_body(prompt, temperature, max_tokens)
        
        # Gemini ç‰¹æ®Šå¤„ç†ï¼šAPI key åœ¨ URL å‚æ•°ä¸­
        if self.provider == 'gemini' and self.api_key:
            url = f"{url}?key={self.api_key}"
        
        try:
            response = requests.post(
                url,
                headers=headers,
                json=body,
                timeout=timeout
            )
            
            if response.status_code != 200:
                logger.error(f"AI APIé”™è¯¯: {response.status_code} - {response.text[:500]}")
                raise Exception(f"AIæœåŠ¡è¿”å›é”™è¯¯: {response.status_code}")
            
            data = response.json()
            content = self.extract_response(data)
            
            if not content:
                raise ValueError("AIè¿”å›å†…å®¹ä¸ºç©º")
            
            return content
            
        except requests.exceptions.Timeout:
            logger.error("AIè¯·æ±‚è¶…æ—¶")
            raise Exception("AIæœåŠ¡è¯·æ±‚è¶…æ—¶")
        except requests.exceptions.ConnectionError:
            logger.error("æ— æ³•è¿æ¥åˆ°AIæœåŠ¡")
            raise Exception("æ— æ³•è¿æ¥åˆ°AIæœåŠ¡ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–APIåœ°å€")
        except Exception as e:
            logger.error(f"AIè¯·æ±‚å¼‚å¸¸: {e}")
            raise

    def get_info(self) -> dict:
        """è·å–å½“å‰é…ç½®ä¿¡æ¯ï¼ˆä¸å«æ•æ„Ÿä¿¡æ¯ï¼‰"""
        return {
            'provider': self.provider,
            'model': self.config.get('model', 'unknown'),
            'configured': self.is_configured(),
            'api_url': self.config.get('api_url', '')[:30] + '...' if self.config.get('api_url') else ''
        }

# åˆå§‹åŒ–AIæä¾›å•†
ai_provider = AIProvider()

# å‘åå…¼å®¹çš„å˜é‡
DEEPSEEK_API_KEY = ai_provider.api_key if ai_provider.provider == 'deepseek' else None
DEEPSEEK_API_URL = ai_provider.config.get('api_url') if ai_provider.provider == 'deepseek' else None

if not ai_provider.is_configured():
    logger.warning("âš ï¸  AIæœåŠ¡æœªé…ç½®ï¼Œè¯·åœ¨.envä¸­è®¾ç½® AI_API_KEY å’Œ AI_PROVIDER")
    logger.info("ğŸ’¡ æ”¯æŒçš„AIæä¾›å•†: deepseek, openai, azure_openai, anthropic, gemini, ollama, openai_compatible")
else:
    info = ai_provider.get_info()
    logger.info(f"âœ… AIæœåŠ¡å·²é…ç½®: {info['provider']} / {info['model']}")

# ==========================================
# å®‰å…¨ä¸­é—´ä»¶å’Œè¾…åŠ©å‡½æ•°
# ==========================================

def sanitize_fund_code(code: str) -> Optional[str]:
    """æ¸…æ´—åŸºé‡‘ä»£ç ï¼Œç¡®ä¿æ˜¯6ä½æ•°å­—"""
    if not code:
        return None
    code = str(code).strip()
    # ç§»é™¤æ‰€æœ‰éæ•°å­—å­—ç¬¦
    code = re.sub(r'\D', '', code)
    # éªŒè¯æ˜¯å¦ä¸º6ä½
    if re.match(r'^\d{6}$', code):
        return code
    return None

def sanitize_input(text: str, max_length: int = 5000) -> str:
    """æ¸…æ´—ç”¨æˆ·è¾“å…¥ï¼Œé˜²æ­¢Prompt Injection"""
    if not text:
        return ""
    # é•¿åº¦é™åˆ¶
    text = text[:max_length]
    # ç§»é™¤æ½œåœ¨çš„å±é™©å­—ç¬¦ï¼ˆä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€å¸¸è§æ ‡ç‚¹ï¼‰
    text = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9\s\.,;:!?\-_(){}\[\]\'"ï¿¥ï¼Œã€‚ï¼›ï¼šï¼ï¼Ÿï¼ˆï¼‰ã€ã€‘]', '', text)
    return text.strip()

def validate_funds_data(funds: list) -> Tuple[bool, str]:
    """éªŒè¯åŸºé‡‘æ•°æ®æ ¼å¼"""
    if not isinstance(funds, list) or len(funds) == 0:
        return False, "åŸºé‡‘åˆ—è¡¨ä¸èƒ½ä¸ºç©º"
    if len(funds) > 20:  # é™åˆ¶æœ€å¤š20åªåŸºé‡‘ï¼Œé˜²æ­¢æ»¥ç”¨
        return False, "å•æ¬¡æœ€å¤šåˆ†æ20åªåŸºé‡‘"
    
    for fund in funds:
        if not isinstance(fund, dict):
            return False, "åŸºé‡‘æ•°æ®æ ¼å¼é”™è¯¯"
        # æ”¯æŒé€šè¿‡ä»£ç æˆ–åç§°ä¸­çš„ä»»æ„ä¸€ä¸ªæ¥è¯†åˆ«åŸºé‡‘
        code = sanitize_fund_code(fund.get('code', ''))
        name = fund.get('name', '').strip()
        
        if not code and not name:
            return False, f"åŸºé‡‘ä»£ç å’Œåç§°ä¸èƒ½åŒæ—¶ä¸ºç©º: {fund}"
        
        # å¦‚æœæœ‰æŒä»“é‡‘é¢ï¼ŒéªŒè¯å…¶æ ¼å¼
        holding = fund.get('holding', 0)
        if holding is not None and holding != '':
            try:
                holding_val = float(holding)
                if holding_val < 0 or holding_val > 100000000:  # é™åˆ¶åˆç†èŒƒå›´
                    return False, "æŒä»“é‡‘é¢è¶…å‡ºåˆç†èŒƒå›´"
            except:
                return False, "æŒä»“é‡‘é¢æ ¼å¼é”™è¯¯"
    return True, ""

# ==========================================
# ç³»ç»Ÿä¸€ï¼šå‡€å€¼å›æ’¤åˆ†ææ¨¡å—ï¼ˆé»˜è®¤90æ—¥é«˜ç‚¹ï¼‰
# ==========================================

def get_fund_drawdown(fund_code="016665", rolling_days=90, target_date=None):
    """
    è·å–åŸºé‡‘å‡€å€¼åŠè·ç¦»è¿‘æœŸé«˜ç‚¹çš„å›æ’¤å¹…åº¦
    è¿”å›çš„drawdown_pctä¸ºæ­£æ•°è¡¨ç¤ºä¸‹è·Œå¹…åº¦ï¼ˆå¦‚10.98è¡¨ç¤ºä¸‹è·Œ10.98%ï¼‰
    åœ¨åˆ†æå™¨ä¸­ä¼šè¢«è½¬æ¢ä¸ºè´Ÿæ•°ç”¨äºæ˜¾ç¤º
    """
    try:
        df = ak.fund_open_fund_info_em(symbol=fund_code, indicator="å•ä½å‡€å€¼èµ°åŠ¿")
    except Exception as e:
        logger.error(f"è·å–æ•°æ®å¤±è´¥ {fund_code}: {e}")
        return None
    
    if df is None or df.empty:
        logger.warning(f"æ— æ³•è·å–åŸºé‡‘ {fund_code} æ•°æ®")
        return None
    
    df = df.iloc[:, :2].copy()
    df.columns = ['date', 'nav']
    df['date'] = pd.to_datetime(df['date'])
    df['nav'] = pd.to_numeric(df['nav'], errors='coerce')
    df = df.dropna().sort_values('date')
    
    if target_date:
        target_dt = pd.to_datetime(target_date)
        target_row = df[df['date'] == target_dt]
        if target_row.empty:
            logger.info(f"æœªæ‰¾åˆ° {target_date} çš„æ•°æ®ï¼Œå°†ä½¿ç”¨æœ€æ–°å¯ç”¨æ•°æ®")
            target_row = df.iloc[-1]
        else:
            target_row = target_row.iloc[0]
    else:
        target_row = df.iloc[-1]
    
    current_nav = float(target_row['nav'])
    current_date = target_row['date']
    
    hist_df = df[df['date'] <= current_date].tail(rolling_days * 2)
    if len(hist_df) < rolling_days:
        logger.warning(f"è¿‘{rolling_days}ä¸ªäº¤æ˜“æ—¥æ•°æ®ä¸è¶³ï¼Œå®é™…åªæœ‰{len(hist_df)}å¤©")
        recent_df = hist_df
    else:
        recent_df = hist_df.tail(rolling_days)
    
    if recent_df.empty:
        logger.warning(f"è¿‘{rolling_days}æ—¥æ— æ•°æ®")
        return None
    
    rolling_high = float(recent_df['nav'].max())
    high_date = recent_df[recent_df['nav'] == rolling_high]['date'].iloc[-1]
    
    # è®¡ç®—å›æ’¤ï¼ˆæ­£æ•°è¡¨ç¤ºä¸‹è·Œç™¾åˆ†æ¯”ï¼‰
    drawdown_pct = float((rolling_high - current_nav) / rolling_high * 100)
    
    result = {
        'fund_code': str(fund_code),
        'current_nav': float(round(current_nav, 4)),
        'current_date': str(current_date.strftime('%Y-%m-%d')),
        'rolling_high': float(round(rolling_high, 4)),
        'high_date': str(high_date.strftime('%Y-%m-%d')),
        'drawdown_pct': float(round(drawdown_pct, 2)),  # æ­£æ•°è¡¨ç¤ºä¸‹è·Œ
        'distance_from_high': float(round(rolling_high - current_nav, 4)),
        'data_points': int(len(recent_df)),
        'is_at_high': bool(abs(drawdown_pct) < 0.01)
    }
    
    return result

# ==========================================
# ç³»ç»ŸäºŒï¼šç›˜ä¸­ä¼°å€¼å¼•æ“
# ==========================================

class SmartFundEstimator:
    def __init__(self):
        self.index_codes = {
            'åˆ›ä¸šæ¿æŒ‡': 'sz399006',
            'æ²ªæ·±300': 'sz399300',
            'ä¸­è¯500': 'sh000905',
            'ä¸Šè¯æŒ‡æ•°': 'sh000001',
            'æ·±è¯æˆæŒ‡': 'sz399001',
            'çº³æ–¯è¾¾å…‹100': 'usQQQ',
            'æ’ç”ŸæŒ‡æ•°': 'hkHSI',
            'æ’ç”Ÿç§‘æŠ€': 'hkHSTECH',
            'ä¸­è¯æ–°èƒ½': 'sz399808',
            'ä¸­è¯ç§‘æŠ€': 'sh000931',
        }
        
        self.etf_map = {
            'äº‘è®¡ç®—': ('516510', 'æ˜“æ–¹è¾¾ä¸­è¯äº‘è®¡ç®—ETF'),
            'å¤§æ•°æ®': ('515400', 'å¯Œå›½ä¸­è¯å¤§æ•°æ®ETF'),
            'äººå·¥æ™ºèƒ½': ('515980', 'åå¯Œä¸­è¯äººå·¥æ™ºèƒ½ETF'),
            'AI': ('515980', 'åå¯Œä¸­è¯äººå·¥æ™ºèƒ½ETF'),
            'èŠ¯ç‰‡': ('512760', 'å›½æ³°CESåŠå¯¼ä½“ETF'),
            'åŠå¯¼ä½“': ('512480', 'å›½è”å®‰ä¸­è¯åŠå¯¼ä½“ETF'),
            'æ–°èƒ½æº': ('516160', 'å—æ–¹ä¸­è¯æ–°èƒ½æºETF'),
            'å…‰ä¼': ('515790', 'åæ³°æŸç‘ä¸­è¯å…‰ä¼ETF'),
            'ç¢³ä¸­å’Œ': ('159790', 'æ˜“æ–¹è¾¾ä¸­è¯ç¢³ä¸­å’ŒETF'),
            'åŒ»ç–—': ('512170', 'åå®ä¸­è¯åŒ»ç–—ETF'),
            'åŒ»è¯': ('512010', 'æ˜“æ–¹è¾¾æ²ªæ·±300åŒ»è¯ETF'),
            'ç™½é…’': ('512690', 'é¹åä¸­è¯é…’ETF'),
            'é…’': ('512690', 'é¹åä¸­è¯é…’ETF'),
            'å†›å·¥': ('512660', 'å›½æ³°ä¸­è¯å†›å·¥ETF'),
            'åˆ¸å•†': ('512000', 'åå®ä¸­è¯å…¨æŒ‡è¯åˆ¸ETF'),
            'è¯åˆ¸': ('512000', 'åå®ä¸­è¯å…¨æŒ‡è¯åˆ¸ETF'),
            'é“¶è¡Œ': ('512800', 'åå®ä¸­è¯é“¶è¡ŒETF'),
            'åœ°äº§': ('512200', 'å—æ–¹ä¸­è¯å…¨æŒ‡æˆ¿åœ°äº§ETF'),
            'æˆ¿åœ°äº§': ('512200', 'å—æ–¹ä¸­è¯å…¨æŒ‡æˆ¿åœ°äº§ETF'),
            'ä¼ åª’': ('512980', 'å¹¿å‘ä¸­è¯ä¼ åª’ETF'),
            'æ¸¸æˆ': ('159869', 'åå¤ä¸­è¯åŠ¨æ¼«æ¸¸æˆETF'),
            'åŠ¨æ¼«æ¸¸æˆ': ('159869', 'åå¤ä¸­è¯åŠ¨æ¼«æ¸¸æˆETF'),
            'ç§‘æŠ€': ('515000', 'åå®ä¸­è¯ç§‘æŠ€é¾™å¤´ETF'),
            '5G': ('515050', 'åå¤ä¸­è¯5Gé€šä¿¡ä¸»é¢˜ETF'),
            'é€šä¿¡': ('515050', 'åå¤ä¸­è¯5Gé€šä¿¡ä¸»é¢˜ETF'),
            'åˆ›æ–°è¯': ('159992', 'é“¶åä¸­è¯åˆ›æ–°è¯äº§ä¸šETF'),
            'æ¶ˆè´¹ç”µå­': ('159732', 'åå¤å›½è¯æ¶ˆè´¹ç”µå­ä¸»é¢˜ETF'),
            'æœºå™¨äºº': ('562500', 'åå¤ä¸­è¯æœºå™¨äººETF'),
            'æœºåºŠ': ('159663', 'åå¤ä¸­è¯æœºåºŠETF'),
            'å·¥ä¸šæ¯æœº': ('159663', 'åå¤ä¸­è¯æœºåºŠETF'),
            'ç¨€æœ‰é‡‘å±': ('159608', 'å˜‰å®ä¸­è¯ç¨€æœ‰é‡‘å±ä¸»é¢˜ETF'),
            'ç¨€åœŸ': ('516780', 'åæ³°æŸç‘ä¸­è¯ç¨€åœŸäº§ä¸šETF'),
            'æœ‰è‰²': ('512400', 'å—æ–¹ä¸­è¯ç”³ä¸‡æœ‰è‰²é‡‘å±ETF'),
            'æœ‰è‰²é‡‘å±': ('512400', 'å—æ–¹ä¸­è¯ç”³ä¸‡æœ‰è‰²é‡‘å±ETF'),
            'åŒ–å·¥': ('516020', 'åå®ä¸­è¯ç»†åˆ†åŒ–å·¥äº§ä¸šETF'),
            'å»ºæ': ('159745', 'å›½æ³°ä¸­è¯å…¨æŒ‡å»ºç­‘ææ–™ETF'),
            'é’¢é“': ('515210', 'å›½æ³°ä¸­è¯é’¢é“ETF'),
            'ç…¤ç‚­': ('515220', 'å›½æ³°ä¸­è¯ç…¤ç‚­ETF'),
            'çŸ³æ²¹': ('501096', 'æ˜“æ–¹è¾¾ä¸­è¯çŸ³åŒ–äº§ä¸šETF'),
            'å†œä¸š': ('159825', 'å¯Œå›½ä¸­è¯å†œä¸šETF'),
            'ç•œç‰§': ('159867', 'é¹åä¸­è¯ç•œç‰§å…»æ®–ETF'),
            'å…»æ®–': ('159867', 'é¹åä¸­è¯ç•œç‰§å…»æ®–ETF'),
            'æ—…æ¸¸': ('159766', 'æ—…æ¸¸ETF'),
            'æ•™è‚²': ('513360', 'æ•™è‚²ETF'),
            'é‡‘èç§‘æŠ€': ('516100', 'é‡‘èç§‘æŠ€ETF'),
            'æ™ºèƒ½åˆ¶é€ ': ('516800', 'æ™ºèƒ½åˆ¶é€ ETF'),
            'é«˜ç«¯åˆ¶é€ ': ('516320', 'é«˜ç«¯åˆ¶é€ ETF'),
            'æ™ºèƒ½æ±½è½¦': ('159889', 'æ™ºèƒ½æ±½è½¦ETF'),
            'æ–°èƒ½æºæ±½è½¦': ('516390', 'æ–°èƒ½æºæ±½è½¦ETF'),
            'æ–°èƒ½æºè½¦': ('515030', 'æ–°èƒ½æºè½¦ETF'),
            'ç”µæ± ': ('159755', 'ç”µæ± ETF'),
            'å‚¨èƒ½': ('159866', 'å‚¨èƒ½ETF'),
            'ç”µåŠ›': ('159611', 'ç”µåŠ›ETF'),
            'ç»¿è‰²ç”µåŠ›': ('159669', 'ç»¿è‰²ç”µåŠ›ETF'),
            'å¤®ä¼': ('512950', 'å¤®ä¼ETF'),
            'å›½ä¼': ('512810', 'å›½ä¼ETF'),
            'çº¢åˆ©': ('510880', 'çº¢åˆ©ETF'),
            'ä½æ³¢åŠ¨': ('512260', 'ä½æ³¢åŠ¨ETF'),
            'ä»·å€¼': ('510030', 'ä»·å€¼ETF'),
            'æˆé•¿': ('510760', 'æˆé•¿ETF'),
            'åˆ›ä¸šæ¿': ('159915', 'åˆ›ä¸šæ¿ETF'),
            'ç§‘åˆ›æ¿': ('588000', 'ç§‘åˆ›50ETF'),
            'ç§‘åˆ›50': ('588000', 'ç§‘åˆ›50ETF'),
            'åŒåˆ›': ('159780', 'åŒåˆ›ETF'),
            'æ²ªæ·±300': ('510300', 'æ²ªæ·±300ETF'),
            'ä¸­è¯500': ('510500', 'ä¸­è¯500ETF'),
            'ä¸­è¯1000': ('512100', 'ä¸­è¯1000ETF'),
            'ä¸Šè¯50': ('510050', 'ä¸Šè¯50ETF'),
            'æ·±è¯100': ('159901', 'æ·±è¯100ETF'),
            'åˆ›ä¸šæ¿50': ('159949', 'åˆ›ä¸šæ¿50ETF'),
            'MSCI': ('512520', 'MSCI ETF'),
            'A50': ('159601', 'A50ETF'),
            'æ²ªæ¸¯æ·±': ('517010', 'æ˜“æ–¹è¾¾ä¸­è¯æ²ªæ¸¯æ·±500ETF'),
        }
        
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        logger.info("â˜… åŸºé‡‘ä¼°å€¼ç³»ç»Ÿ v6.0 [ç²¾ç®€ç‰ˆ - ä»…ä¼°å€¼ä¸å›æ’¤]")

    def is_link_fund(self, fund_name: str) -> bool:
        return bool(re.search(r'è”æ¥|link', fund_name, re.IGNORECASE))

    def is_etf_code(self, code: str, name: str) -> bool:
        code = str(code).strip()
        if re.match(r'^(510|511|512|515|516|517|518|560|561|562|563|564|565|566|567|568|569|159)\d{3}$', code):
            return True
        if 'ETF' in name or 'etf' in name:
            return True
        return False

    def find_etf_by_fund_name(self, fund_name: str) -> Tuple[Optional[str], Optional[str]]:
        clean = re.sub(r'è”æ¥[ABC]?|Link|[A-C]$', '', fund_name, flags=re.IGNORECASE).strip()
        
        for keyword, (code, name) in self.etf_map.items():
            if keyword in clean:
                return code, name
        
        companies = ['æ˜“æ–¹è¾¾', 'åå¤', 'å—æ–¹', 'å›½æ³°', 'åå®', 'å¹¿å‘', 'å¯Œå›½', 'å˜‰å®', 
                     'åæ³°æŸç‘', 'é¹å', 'é“¶å', 'å›½è”å®‰', 'åå¯Œ', 'æ±‡æ·»å¯Œ', 'å·¥é“¶', 'åšæ—¶']
        for comp in companies:
            if clean.startswith(comp):
                keyword = clean[len(comp):].strip()
                for kw, (code, name) in self.etf_map.items():
                    if kw in keyword:
                        return code, name
                break
        
        return None, None

    def detect_market_and_benchmark(self, holdings_df, fund_name: str) -> Tuple[str, str, float]:
        us_count = 0
        hk_count = 0
        a_sh_count = 0
        a_sz_count = 0
        
        for _, row in holdings_df.iterrows():
            code = str(row['è‚¡ç¥¨ä»£ç ']).strip()
            
            if re.match(r'^[A-Z]{1,5}(\.[A-Z])?$', code):
                us_count += 1
            elif re.match(r'^\d{5}$', code):
                hk_count += 1
            elif len(code) == 6 and code.isdigit():
                if code.startswith('6'):
                    a_sh_count += 1
                else:
                    a_sz_count += 1
        
        total = us_count + hk_count + a_sh_count + a_sz_count
        
        if us_count >= 3 or (total > 0 and us_count / total > 0.5):
            market = 'ç¾è‚¡'
            benchmark = 'çº³æ–¯è¾¾å…‹100'
            position = 0.90
        elif hk_count >= 3 or (total > 0 and hk_count / total > 0.5):
            market = 'æ¸¯è‚¡'
            if 'ç§‘æŠ€' in fund_name:
                benchmark = 'æ’ç”Ÿç§‘æŠ€'
            else:
                benchmark = 'æ’ç”ŸæŒ‡æ•°'
            position = 0.88
        else:
            market = 'Aè‚¡'
            gem_count = sum(1 for _, row in holdings_df.iterrows() 
                          if str(row['è‚¡ç¥¨ä»£ç ']).startswith('300'))
            if gem_count >= 4:
                benchmark = 'åˆ›ä¸šæ¿æŒ‡'
            elif a_sh_count > a_sz_count:
                benchmark = 'æ²ªæ·±300'
            else:
                benchmark = 'åˆ›ä¸šæ¿æŒ‡' if gem_count >= 2 else 'æ²ªæ·±300'
            position = 0.90 if (gem_count >= 4) else 0.88
        
        return market, benchmark, position

    def get_stock_changes(self, codes: List[str], names: List[str]) -> Dict[str, float]:
        results = {}
        if not codes:
            return results
            
        tencent_codes = []
        mapping = {}
        
        for code, name in zip(codes, names):
            code = str(code).strip()
            
            if len(code) == 6 and code.isdigit():
                if code.startswith(('5', '1')):
                    prefix = 'sh' if code.startswith('5') else 'sz'
                    tcode = f"{prefix}{code}"
                elif code.startswith('6'):
                    tcode = f"sh{code}"
                else:
                    tcode = f"sz{code}"
            elif len(code) == 5 and code.isdigit():
                tcode = f"hk{code}"
            else:
                tcode = f"us{code.replace('.', '_')}"
            
            tencent_codes.append(tcode)
            mapping[tcode] = code
        
        for i in range(0, len(tencent_codes), 60):
            batch = tencent_codes[i:i+60]
            try:
                url = f"http://qt.gtimg.cn/q={','.join(batch)}"
                resp = requests.get(url, headers=self.headers, timeout=15)
                resp.encoding = 'gbk'
                
                for line in resp.text.split(';'):
                    if '=' not in line:
                        continue
                    parts = line.split('=')
                    if len(parts) < 2:
                        continue
                    
                    match = re.search(r'(us[A-Z_]+|sh\d{6}|sz\d{6}|hk\d{5})', parts[0])
                    if not match:
                        continue
                    
                    tcode = match.group(0)
                    orig_code = mapping.get(tcode)
                    if not orig_code:
                        continue
                    
                    fields = parts[1].strip('"').split('~')
                    if len(fields) > 32:
                        try:
                            change = float(fields[32]) if fields[32] else 0.0
                            if change == 0 and len(fields) > 4:
                                curr = float(fields[3]) if fields[3] else 0
                                prev = float(fields[4]) if fields[4] else 0
                                if prev > 0:
                                    change = (curr - prev) / prev * 100
                            results[orig_code] = change
                        except:
                            results[orig_code] = 0.0
            except Exception as e:
                logger.error(f"è¡Œæƒ…æ¥å£é”™è¯¯: {e}")
            
            time.sleep(0.2)
        
        return results

    def get_index_change(self, index_name: str) -> float:
        code = self.index_codes.get(index_name, 'sz399006')
        try:
            url = f"http://qt.gtimg.cn/q={code}"
            resp = requests.get(url, headers=self.headers, timeout=10)
            resp.encoding = 'gbk'
            if '=' in resp.text:
                fields = resp.text.split('=')[1].strip('"').split('~')
                if len(fields) > 32:
                    return float(fields[32]) if fields[32] else 0.0
        except:
            pass
        return 0.0

    def estimate_link_fund(self, fund_code: str, fund_name: str, holding: float) -> Optional[Dict]:
        logger.info(f"\nã€{fund_name}ã€‘{fund_code} [è”æ¥åŸºé‡‘æ¨¡å¼]")
        
        try:
            df = ak.fund_portfolio_hold_em(symbol=fund_code, date="2025")
            if df.empty:
                df = ak.fund_portfolio_hold_em(symbol=fund_code, date="2024")
            
            etf_code = None
            etf_name = None
            etf_ratio = 95.0
            
            if not df.empty:
                latest_q = sorted(df['å­£åº¦'].unique(), reverse=True)[0]
                data = df[df['å­£åº¦'] == latest_q]
                
                if len(data) > 0:
                    top1 = data.iloc[0]
                    top1_ratio = float(top1['å å‡€å€¼æ¯”ä¾‹'])
                    top1_name = str(top1['è‚¡ç¥¨åç§°'])
                    top1_code = str(top1['è‚¡ç¥¨ä»£ç '])
                    
                    if top1_ratio > 80 and self.is_etf_code(top1_code, top1_name):
                        etf_code = top1_code
                        etf_name = top1_name
                        etf_ratio = top1_ratio
                        logger.info(f"  ç›®æ ‡ETF: {etf_name}({etf_code}) å æ¯”{etf_ratio:.1f}%")
                    else:
                        logger.warning(f"  è­¦å‘Šï¼šæŒä»“å æ¯”è¿‡ä½({top1_ratio}%)ï¼Œakshareè¿”å›äº†æˆåˆ†è‚¡")
                        logger.info(f"  å°è¯•é€šè¿‡åŸºé‡‘åç§°åå‘æŸ¥æ‰¾ETF...")
            
            if not etf_code:
                etf_code, etf_name = self.find_etf_by_fund_name(fund_name)
                if etf_code:
                    logger.info(f"  åå‘æŸ¥æ‰¾ETF: {etf_name}({etf_code}) é¢„ä¼°å æ¯”{etf_ratio:.1f}%")
                else:
                    logger.warning(f"  æœªèƒ½æ‰¾åˆ°å¯¹åº”ETFï¼Œå›é€€åˆ°æ™®é€šæ¨¡å¼")
                    return self.estimate_normal_fund(fund_code, fund_name, holding, df)
            
            etf_changes = self.get_stock_changes([etf_code], [etf_name])
            etf_change = etf_changes.get(etf_code, 0)
            
            if etf_change == 0:
                logger.warning(f"  æœªèƒ½è·å–ETFè¡Œæƒ…")
                return None
            
            position = min(etf_ratio * 1.02, 98) / 100
            link_change = etf_change * position
            profit = holding * link_change / 100
            
            logger.info(f"  ETFè¡Œæƒ…: {etf_change:+.2f}% | ä»“ä½ç³»æ•°: {position*100:.0f}%")
            logger.info(f"  ç»“æœ: {link_change:+.2f}% | ç›ˆäº: {profit:+,.0f}å…ƒ")
            
            return {
                'fund_code': str(fund_code),
                'fund_name': str(fund_name),
                'market': 'Aè‚¡-è”æ¥',
                'holding': float(holding),
                'benchmark': str(etf_name),
                'benchmark_change': float(round(etf_change, 2)),
                'estimate_change': float(round(link_change, 2)),
                'profit': float(round(profit, 2)),
                'top10_ratio': float(round(etf_ratio, 1)),
                'position_ratio': float(round(position * 100, 0)),
                'persistence': 1.0,
                'note': f'è·Ÿè¸ª{etf_code}',
                'update_time': datetime.now().strftime('%H:%M:%S')
            }
            
        except Exception as e:
            logger.error(f"  è”æ¥åŸºé‡‘å¤„ç†å¤±è´¥: {e}")
            return self.estimate_normal_fund(fund_code, fund_name, holding)

    def estimate_normal_fund(self, fund_code: str, fund_name: str, holding: float, df=None) -> Optional[Dict]:
        try:
            if df is None:
                df = ak.fund_portfolio_hold_em(symbol=fund_code, date="2025")
                if df.empty:
                    df = ak.fund_portfolio_hold_em(symbol=fund_code, date="2024")
                if df.empty:
                    return None
            
            latest_q = sorted(df['å­£åº¦'].unique(), reverse=True)[0]
            data = df[df['å­£åº¦'] == latest_q].head(10)
            
            stocks = []
            for _, row in data.iterrows():
                stocks.append({
                    'code': str(row['è‚¡ç¥¨ä»£ç ']),
                    'name': str(row['è‚¡ç¥¨åç§°']),
                    'ratio': float(row['å å‡€å€¼æ¯”ä¾‹'])
                })
            
            if not stocks:
                return None
            
            market, benchmark, est_position = self.detect_market_and_benchmark(data, fund_name)
            logger.info(f"  æ£€æµ‹å¸‚åœº: {market} | åŸºå‡†: {benchmark} | ä¼°ç®—ä»“ä½: {est_position*100:.0f}%")
            
            codes = [s['code'] for s in stocks]
            names = [s['name'] for s in stocks]
            changes = self.get_stock_changes(codes, names)
            
            top10_contrib = 0
            valid_count = 0
            for s in stocks:
                chg = changes.get(s['code'], 0)
                if chg != 0:
                    top10_contrib += chg * s['ratio'] / 100
                    valid_count += 1
                    logger.info(f"  {s['code']}({s['name']}): {chg:+.2f}% Ã— {s['ratio']}% = {chg * s['ratio'] / 100:+.3f}%")
            
            if valid_count == 0:
                return None
            
            top10_ratio = sum(s['ratio'] for s in stocks)
            bench_chg = self.get_index_change(benchmark)
            logger.info(f"  åŸºå‡†{benchmark}: {bench_chg:+.2f}%")
            
            remaining_ratio = max(0, est_position * 100 - top10_ratio)
            remaining_contrib = bench_chg * (remaining_ratio / 100)
            
            total_change = top10_contrib + remaining_contrib
            
            if market == 'ç¾è‚¡':
                total_change *= 1.10
            elif market == 'æ¸¯è‚¡':
                if 'ç§‘æŠ€' in fund_name:
                    total_change *= 1.20
                else:
                    total_change *= 1.15
            elif 'ç§‘æŠ€' in fund_name or 'ç§‘è' in fund_name:
                total_change *= 1.20
            elif 'ç¢³ä¸­å’Œ' in fund_name or 'æ–°èƒ½æº' in fund_name:
                total_change *= 1.30
            
            profit = holding * total_change / 100
            
            logger.info(f"  å‰åå æ¯”: {top10_ratio:.1f}% | å‰©ä½™è¡¥é½: {remaining_ratio:.1f}%")
            logger.info(f"  ç»“æœ: {total_change:+.2f}% | ç›ˆäº: {profit:+,.0f}å…ƒ")
            
            return {
                'fund_code': str(fund_code),
                'fund_name': str(fund_name),
                'market': str(market),
                'holding': float(holding),
                'benchmark': str(benchmark),
                'benchmark_change': float(round(bench_chg, 2)),
                'estimate_change': float(round(total_change, 2)),
                'profit': float(round(profit, 2)),
                'top10_ratio': float(round(top10_ratio, 1)),
                'position_ratio': float(round(est_position * 100, 0)),
                'persistence': 0.75 if market == 'ç¾è‚¡' else (0.65 if market == 'æ¸¯è‚¡' else 0.55),
                'update_time': datetime.now().strftime('%H:%M:%S')
            }
            
        except Exception as e:
            logger.error(f"  æ™®é€šåŸºé‡‘ä¼°ç®—å¤±è´¥: {e}")
            return None

    def estimate_fund(self, fund_code: str, fund_name: str, holding: float) -> Optional[Dict]:
        if self.is_link_fund(fund_name):
            return self.estimate_link_fund(fund_code, fund_name, holding)
        else:
            return self.estimate_normal_fund(fund_code, fund_name, holding)


# ==========================================
# æ•´åˆå±‚ï¼šä¼°å€¼ä¸å›æ’¤åˆ†æå™¨ï¼ˆç²¾ç®€ç‰ˆï¼‰
# ==========================================

class FundAnalyzer:
    """
    åŸºé‡‘åˆ†æå™¨ - ç²¾ç®€ç‰ˆ
    ä»…æä¾›å®æ—¶ä¼°å€¼å’Œæ»šåŠ¨å›æ’¤æ•°æ®ï¼Œä¸åŒ…å«æŠ•èµ„å»ºè®®
    """
    
    def __init__(self):
        self.estimator = SmartFundEstimator()
    
    def get_fund_risk_metrics(self, fund_code: str) -> Optional[Dict]:
        """
        è·å–åŸºé‡‘é£é™©æŒ‡æ ‡ï¼šå¤æ™®æ¯”ç‡ã€å¹´åŒ–æ³¢åŠ¨ç‡ã€æœ€å¤§å›æ’¤ã€åŒç±»æ’å
        """
        try:
            logger.info(f"\n[æ­¥éª¤4] è·å–åŸºé‡‘é£é™©æŒ‡æ ‡...")
            logger.info(f"  åŸºé‡‘ä»£ç : {fund_code}")
            
            # è°ƒç”¨akshareæ¥å£è·å–é£é™©æŒ‡æ ‡æ•°æ®
            logger.info(f"  è°ƒç”¨ak.fund_individual_analysis_xqæ¥å£...")
            df = ak.fund_individual_analysis_xq(symbol=fund_code)
            
            logger.info(f"  æ¥å£è¿”å›æ•°æ®ç±»å‹: {type(df)}")
            if df is not None:
                logger.info(f"  æ¥å£è¿”å›æ•°æ®å½¢çŠ¶: {df.shape}")
                logger.info(f"  æ¥å£è¿”å›æ•°æ®å‰5è¡Œ: {df.head().to_dict()}")
            
            if df is None or df.empty:
                logger.warning(f"æ— æ³•è·å–åŸºé‡‘ {fund_code} é£é™©æŒ‡æ ‡æ•°æ®")
                return None
            
            # æå–éœ€è¦çš„æ•°æ®
            risk_metrics = {
                'sharpe_ratio': None,
                'annual_volatility': None,
                'max_drawdown': None,
                'rank_1y': None,
                'rank_3y': None,
                'rank_5y': None
            }
            
            # éå†æ•°æ®è¡Œï¼Œæå–æ‰€éœ€æŒ‡æ ‡
            logger.info(f"  å¼€å§‹æå–é£é™©æŒ‡æ ‡æ•°æ®...")
            for index, row in df.iterrows():
                period = str(row.get('å‘¨æœŸ', '')).strip()
                logger.info(f"  è¡Œ {index}: å‘¨æœŸ={period}")
                
                if 'è¿‘1å¹´' in period:
                    # æå–è¿‘1å¹´æ•°æ®
                    try:
                        risk_metrics['sharpe_ratio'] = float(row.get('å¹´åŒ–å¤æ™®æ¯”ç‡', None))
                        logger.info(f"  æå–è¿‘1å¹´å¤æ™®æ¯”ç‡æˆåŠŸ: {risk_metrics['sharpe_ratio']}")
                    except Exception as e:
                        logger.warning(f"  æå–è¿‘1å¹´å¤æ™®æ¯”ç‡å¤±è´¥: {e}")
                        pass
                    
                    try:
                        risk_metrics['annual_volatility'] = float(row.get('å¹´åŒ–æ³¢åŠ¨ç‡', None))
                        logger.info(f"  æå–è¿‘1å¹´å¹´åŒ–æ³¢åŠ¨ç‡æˆåŠŸ: {risk_metrics['annual_volatility']}")
                    except Exception as e:
                        logger.warning(f"  æå–è¿‘1å¹´å¹´åŒ–æ³¢åŠ¨ç‡å¤±è´¥: {e}")
                        pass
                    
                    try:
                        max_drawdown = float(row.get('æœ€å¤§å›æ’¤', None))
                        risk_metrics['max_drawdown'] = -max_drawdown  # è½¬æ¢ä¸ºè´Ÿæ•°è¡¨ç¤ºä¸‹è·Œ
                        logger.info(f"  æå–è¿‘1å¹´æœ€å¤§å›æ’¤æˆåŠŸ: {risk_metrics['max_drawdown']}")
                    except Exception as e:
                        logger.warning(f"  æå–è¿‘1å¹´æœ€å¤§å›æ’¤å¤±è´¥: {e}")
                        pass
                    
                    try:
                        risk_metrics['rank_1y'] = str(row.get('è¾ƒåŒç±»é£é™©æ”¶ç›Šæ¯”', None))
                        logger.info(f"  æå–è¿‘1å¹´åŒç±»æ’åæˆåŠŸ: {risk_metrics['rank_1y']}")
                    except Exception as e:
                        logger.warning(f"  æå–è¿‘1å¹´åŒç±»æ’åå¤±è´¥: {e}")
                        pass
                
                elif 'è¿‘3å¹´' in period:
                    # æå–è¿‘3å¹´æ•°æ®
                    try:
                        risk_metrics['rank_3y'] = str(row.get('è¾ƒåŒç±»é£é™©æ”¶ç›Šæ¯”', None))
                        logger.info(f"  æå–è¿‘3å¹´åŒç±»æ’åæˆåŠŸ: {risk_metrics['rank_3y']}")
                    except Exception as e:
                        logger.warning(f"  æå–è¿‘3å¹´åŒç±»æ’åå¤±è´¥: {e}")
                        pass
                
                elif 'è¿‘5å¹´' in period:
                    # æå–è¿‘5å¹´æ•°æ®
                    try:
                        risk_metrics['rank_5y'] = str(row.get('è¾ƒåŒç±»é£é™©æ”¶ç›Šæ¯”', None))
                        logger.info(f"  æå–è¿‘5å¹´åŒç±»æ’åæˆåŠŸ: {risk_metrics['rank_5y']}")
                    except Exception as e:
                        logger.warning(f"  æå–è¿‘5å¹´åŒç±»æ’åå¤±è´¥: {e}")
                        pass
            
            logger.info(f"  é£é™©æŒ‡æ ‡è·å–æˆåŠŸ: {risk_metrics}")
            return risk_metrics
            
        except Exception as e:
            logger.error(f"è·å–åŸºé‡‘é£é™©æŒ‡æ ‡å¤±è´¥ {fund_code}: {e}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            return None
    
    def analyze_fund(self, fund_code: str, fund_name: str, holding: float) -> Optional[Dict]:
        """
        åˆ†æå•åªåŸºé‡‘ï¼šä¼°å€¼ + å›æ’¤(90æ—¥)
        """
        logger.info(f"\n{'='*60}")
        logger.info(f"å¼€å§‹åˆ†æåŸºé‡‘: {fund_code} ({fund_name})")
        logger.info(f"{'='*60}")
        
        # 1. è·å–å®æ—¶ä¼°å€¼
        logger.info("\n[æ­¥éª¤1] è·å–å®æ—¶ä¼°å€¼...")
        estimate_result = self.estimator.estimate_fund(fund_code, fund_name, holding)
        if not estimate_result:
            logger.error("  å®æ—¶ä¼°å€¼è·å–å¤±è´¥")
            return None
        
        today_change = estimate_result['estimate_change']
        
        # 2. è·å–å†å²å›æ’¤ï¼ˆ90æ—¥çª—å£ï¼‰
        logger.info("\n[æ­¥éª¤2] è·å–90æ—¥æ»šåŠ¨é«˜ç‚¹å›æ’¤...")
        drawdown_result = get_fund_drawdown(fund_code, rolling_days=90, target_date=None)
        if not drawdown_result:
            logger.error("  å†å²å›æ’¤æ•°æ®è·å–å¤±è´¥")
            return None
        
        # å¼ºåˆ¶è½¬æ¢æ‰€æœ‰numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹
        historical_drawdown_pos = float(drawdown_result['drawdown_pct'])  # æ­£æ•°è¡¨ç¤ºä¸‹è·Œï¼ˆå¦‚10.98ï¼‰
        yesterday_nav = float(drawdown_result['current_nav'])
        rolling_high = float(drawdown_result['rolling_high'])
        
        # è½¬æ¢ä¸ºè´Ÿæ•°è¡¨ç¤ºä¸‹è·Œï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
        historical_drawdown_neg = -historical_drawdown_pos  # -10.98
        
        # 3. è®¡ç®—é¢„ä¼°å›æ’¤ï¼ˆè´Ÿæ•°è¡¨ç¤ºä¸‹è·Œï¼‰
        estimated_nav = yesterday_nav * (1 + today_change / 100)
        estimated_drawdown = (estimated_nav - rolling_high) / rolling_high * 100  # è´Ÿæ•°ï¼ˆå¦‚-11.65ï¼‰
        
        # 4. è·å–é£é™©æŒ‡æ ‡
        risk_metrics = self.get_fund_risk_metrics(fund_code)
        
        # ç¡®ä¿risk_metricsä¸ä¸ºNoneï¼Œè€Œæ˜¯ä¸€ä¸ªç©ºå­—å…¸
        if risk_metrics is None:
            risk_metrics = {
                'sharpe_ratio': None,
                'annual_volatility': None,
                'max_drawdown': None,
                'rank_1y': None,
                'rank_3y': None,
                'rank_5y': None
            }
        
        logger.info(f"\n[æ­¥éª¤3] è®¡ç®—åˆæˆæŒ‡æ ‡...")
        logger.info(f"  æ˜¨æ—¥å‡€å€¼: {yesterday_nav}")
        logger.info(f"  90æ—¥é«˜ç‚¹: {rolling_high} ({drawdown_result['high_date']})")
        logger.info(f"  å†å²å›æ’¤: {historical_drawdown_neg:.2f}%")
        logger.info(f"  ä»Šæ—¥ä¼°å€¼: {today_change:+.2f}%")
        logger.info(f"  é¢„ä¼°å‡€å€¼: {estimated_nav:.4f}")
        logger.info(f"  é¢„ä¼°å›æ’¤: {estimated_drawdown:.2f}%")
        logger.info(f"  é£é™©æŒ‡æ ‡: {risk_metrics}")
        
        # 5. ç»„è£…å®Œæ•´ç»“æœï¼ˆç¡®ä¿æ‰€æœ‰ç±»å‹å¯JSONåºåˆ—åŒ–ï¼‰
        result = {
            'fund_code': str(fund_code),
            'fund_name': str(fund_name),
            'holding': float(holding),
            
            'real_time_estimate': {
                'today_change_pct': float(estimate_result['estimate_change']),
                'estimated_nav': float(round(estimated_nav, 4)),
                'market': str(estimate_result.get('market', 'æœªçŸ¥')),
                'benchmark': str(estimate_result.get('benchmark', 'æœªçŸ¥')),
                'update_time': str(estimate_result.get('update_time', datetime.now().strftime('%H:%M:%S')))
            },
            
            'historical_drawdown': {
                'yesterday_nav': float(yesterday_nav),
                'rolling_high_90d': float(rolling_high),
                'high_date': str(drawdown_result['high_date']),
                'drawdown_to_high_pct': float(historical_drawdown_neg),  # è´Ÿæ•°è¡¨ç¤ºä¸‹è·Œ
                'is_at_rolling_high': bool(abs(estimated_drawdown) < 0.01)
            },
            
            'synthetic_forecast': {
                'estimated_drawdown_pct': float(round(estimated_drawdown, 2)),  # è´Ÿæ•°è¡¨ç¤ºä¸‹è·Œ
                'drawdown_change_today': float(round(estimated_drawdown - historical_drawdown_neg, 2))
            },
            
            'risk_metrics': risk_metrics,
            
            'raw_estimate_data': estimate_result
        }
        
        logger.info(f"\n[ç»“æœ] {fund_code} åˆ†æå®Œæˆ")
        
        return result


# ==========================================
# AI æœåŠ¡å±‚ï¼ˆä»…ç”¨äºè§£æåŸºé‡‘è¾“å…¥ï¼‰
# ==========================================

class AIService:
    """AIæœåŠ¡å°è£…ï¼Œä»…ç”¨äºè§£æè‡ªç„¶è¯­è¨€è¾“å…¥"""
    
    @staticmethod
    def parse_funds_natural_language(text: str) -> List[Dict]:
        """
        ä½¿ç”¨AIè§£æè‡ªç„¶è¯­è¨€è¾“å…¥ï¼Œæå–åŸºé‡‘ä¿¡æ¯
        æ”¯æŒä»…è¾“å…¥åŸºé‡‘ä»£ç æˆ–åŸºé‡‘åç§°ï¼Œä¹Ÿæ”¯æŒä¸è¾“å…¥é‡‘é¢
        è¿”å›: [{"code": "...", "name": "...", "holding": ...}, ...]
        """
        if not ai_provider.is_configured():
            raise ValueError("AIæœåŠ¡æœªé…ç½®")
        
        # æ¸…æ´—è¾“å…¥
        text = sanitize_input(text, max_length=3000)
        
        prompt = f"""è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–åŸºé‡‘ä¿¡æ¯ï¼Œè¿”å›æ ‡å‡†JSONæ•°ç»„æ ¼å¼ã€‚æ¯ä¸ªå¯¹è±¡å¯åŒ…å«code(åŸºé‡‘ä»£ç ,6ä½æ•°å­—)ã€name(åŸºé‡‘åç§°)ã€holding(æŒä»“é‡‘é¢,æ•°å­—)ã€‚
é‡è¦è§„åˆ™ï¼š
1. åŸºé‡‘ä»£ç é€šå¸¸æ˜¯6ä½æ•°å­—ï¼Œå¦‚æœç”¨æˆ·åªè¾“å…¥åç§°æ²¡æœ‰ä»£ç ï¼Œåˆ™codeå­—æ®µç•™ç©ºæˆ–çœç•¥
2. å¦‚æœç”¨æˆ·åªè¾“å…¥ä»£ç æ²¡æœ‰åç§°ï¼Œåˆ™nameå­—æ®µç•™ç©ºæˆ–çœç•¥
3. é‡‘é¢æ”¯æŒ"å…ƒ","å—","ä¸‡"ç­‰å•ä½ï¼Œè½¬æ¢ä¸ºçº¯æ•°å­—ï¼ˆå¦‚1.5ä¸‡è½¬æ¢ä¸º15000ï¼‰
4. å¦‚æœç”¨æˆ·æ²¡æœ‰è¾“å…¥é‡‘é¢ï¼Œholdingå­—æ®µå¯ä»¥ä¸º0ã€nullæˆ–çœç•¥
5. åªè¿”å›JSONæ•°ç»„ï¼Œä¸è¦ä»»ä½•å…¶ä»–æ–‡å­—ã€è§£é‡Šæˆ–markdownæ ¼å¼

æ–‡æœ¬ï¼š{text}

ç¤ºä¾‹è¾“å‡ºï¼š
- å®Œæ•´ä¿¡æ¯ï¼š[{{"code":"110011","name":"æ˜“æ–¹è¾¾è“ç­¹","holding":10000}}]
- åªæœ‰ä»£ç ï¼š[{{"code":"110011","holding":0}}]
- åªæœ‰åç§°ï¼š[{{"name":"æ˜“æ–¹è¾¾è“ç­¹","holding":0}}]
- åªæœ‰ä»£ç å’Œé‡‘é¢ï¼š[{{"code":"110011","holding":5000}}]"""

        try:
            content = ai_provider.chat(prompt, temperature=0.1, max_tokens=2000, timeout=30)
            
            # æå–JSONæ•°ç»„
            json_match = re.search(r'\[[\s\S]*?\]', content)
            if not json_match:
                raise ValueError("AIè¿”å›æ ¼å¼é”™è¯¯")
            
            funds = json.loads(json_match[0])
            
            # éªŒè¯å’Œæ¸…æ´—ç»“æœï¼Œå¹¶è¡¥å…¨ä¿¡æ¯
            valid_funds = []
            for fund in funds:
                code = sanitize_fund_code(fund.get('code', ''))
                name = fund.get('name', '').strip()
                
                # å¤„ç†æŒä»“é‡‘é¢
                try:
                    holding = float(fund.get('holding', 0) or 0)
                    if holding < 0:
                        holding = 0
                except:
                    holding = 0
                
                # æƒ…å†µ1: æœ‰ä»£ç ï¼Œå¯èƒ½æœ‰åç§° - ç›´æ¥ä½¿ç”¨
                if code:
                    # å¦‚æœæ²¡æœ‰åç§°ï¼Œå°è¯•ä»åŸºé‡‘åˆ—è¡¨æŸ¥æ‰¾
                    if not name:
                        fund_info = FundSearchService.get_fund_by_code(code)
                        if fund_info:
                            name = fund_info['name']
                    
                    valid_funds.append({
                        'code': code,
                        'name': name[:50] if name else code,
                        'holding': holding
                    })
                
                # æƒ…å†µ2: åªæœ‰åç§°æ²¡æœ‰ä»£ç  - æœç´¢åŒ¹é…çš„åŸºé‡‘
                elif name and not code:
                    search_results = FundSearchService.search_fund(name, limit=5)
                    if search_results:
                        # å°è¯•ç²¾ç¡®åŒ¹é…
                        matched = None
                        for result in search_results:
                            if result['name'] == name:
                                matched = result
                                break
                        # å¦‚æœæ²¡æœ‰ç²¾ç¡®åŒ¹é…ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªç»“æœ
                        if not matched:
                            matched = search_results[0]
                        
                        valid_funds.append({
                            'code': matched['code'],
                            'name': matched['name'],
                            'holding': holding
                        })
                        logger.info(f"é€šè¿‡åç§°æœç´¢åˆ°åŸºé‡‘: {name} -> {matched['code']} {matched['name']}")
                    else:
                        logger.warning(f"æœªæ‰¾åˆ°ä¸åç§°åŒ¹é…çš„åŸºé‡‘: {name}")
            
            return valid_funds
            
        except json.JSONDecodeError as e:
            logger.error(f"JSONè§£æé”™è¯¯: {e}, å†…å®¹: {content}")
            raise ValueError("AIè¿”å›æ•°æ®è§£æå¤±è´¥")
        except Exception as e:
            logger.error(f"AIè§£æé”™è¯¯: {e}")
            raise


# ==========================================
# åŸºé‡‘æœç´¢æœåŠ¡
# ==========================================

class FundSearchService:
    """åŸºé‡‘æœç´¢æœåŠ¡ - åŸºäºakshareåŸºé‡‘åˆ—è¡¨"""
    
    _fund_list_cache = None
    _cache_time = None
    _cache_duration = 3600  # ç¼“å­˜1å°æ—¶
    
    # åˆ—åå¸¸é‡ï¼ˆé¿å…Windowsç¼–ç é—®é¢˜ï¼‰
    COL_CODE = '\u57fa\u91d1\u4ee3\u7801'  # åŸºé‡‘ä»£ç 
    COL_NAME = '\u57fa\u91d1\u7b80\u79f0'  # åŸºé‡‘ç®€ç§°
    COL_PINYIN_ABBR = '\u62fc\u97f3\u7f29\u5199'  # æ‹¼éŸ³ç¼©å†™
    COL_TYPE = '\u57fa\u91d1\u7c7b\u578b'  # åŸºé‡‘ç±»å‹
    COL_PINYIN_FULL = '\u62fc\u97f3\u5168\u79f0'  # æ‹¼éŸ³å…¨ç§°
    
    # å€’æ’ç´¢å¼•ç¼“å­˜
    _inverted_index = None
    _code_to_fund = None
    
    @classmethod
    def get_fund_list(cls) -> pd.DataFrame:
        """è·å–åŸºé‡‘åˆ—è¡¨ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        now = time.time()
        
        if cls._fund_list_cache is not None and cls._cache_time is not None:
            if now - cls._cache_time < cls._cache_duration:
                return cls._fund_list_cache
        
        try:
            df = ak.fund_name_em()
            cls._fund_list_cache = df
            cls._cache_time = now
            # é‡å»ºç´¢å¼•
            cls._build_indexes(df)
            logger.info(f"\u57fa\u91d1\u5217\u8868\u7f13\u5b58\u5df2\u66f4\u65b0\uff0c\u5171{len(df)}\u6761\u8bb0\u5f55")
            return df
        except Exception as e:
            logger.error(f"\u83b7\u53d6\u57fa\u91d1\u5217\u8868\u5931\u8d25: {e}")
            if cls._fund_list_cache is not None:
                return cls._fund_list_cache
            raise
    
    @classmethod
    def _build_indexes(cls, df: pd.DataFrame):
        """æ„å»ºæœç´¢ç´¢å¼•"""
        cls._inverted_index = {}
        cls._code_to_fund = {}
        
        try:
            for idx, row in df.iterrows():
                try:
                    code = str(row[cls.COL_CODE])
                    name = str(row.get(cls.COL_NAME, '')).strip()
                    pinyin_abbr = str(row.get(cls.COL_PINYIN_ABBR, '')).strip().upper()
                    fund_type = str(row.get(cls.COL_TYPE, '')).strip()
                    
                    # æ„å»ºåŸºé‡‘ä¿¡æ¯
                    fund_info = {
                        'code': code,
                        'name': name,
                        'pinyin': pinyin_abbr,
                        'type': fund_type
                    }
                    
                    # ä»£ç åˆ°åŸºé‡‘çš„æ˜ å°„
                    cls._code_to_fund[code] = fund_info
                    
                    # æ„å»ºå€’æ’ç´¢å¼•
                    # 1. ä»£ç ç´¢å¼•
                    for i in range(len(code)):
                        prefix = code[:i+1]
                        if prefix not in cls._inverted_index:
                            cls._inverted_index[prefix] = set()
                        cls._inverted_index[prefix].add(code)
                    
                    # 2. åç§°ç´¢å¼•
                    if name:
                        # å…¨åç§°
                        name_lower = name.lower()
                        for i in range(len(name_lower)):
                            for j in range(i+1, min(i+10, len(name_lower)+1)):
                                substr = name_lower[i:j]
                                if substr not in cls._inverted_index:
                                    cls._inverted_index[substr] = set()
                                cls._inverted_index[substr].add(code)
                    
                    # 3. æ‹¼éŸ³ç¼©å†™ç´¢å¼•
                    if pinyin_abbr:
                        for i in range(len(pinyin_abbr)):
                            prefix = pinyin_abbr[:i+1]
                            if prefix not in cls._inverted_index:
                                cls._inverted_index[prefix] = set()
                            cls._inverted_index[prefix].add(code)
                            
                except Exception as e:
                    logger.debug(f"å¤„ç†åŸºé‡‘æ•°æ®æ—¶å‡ºé”™: {e}")
                    continue
        except Exception as e:
            logger.error(f"æ„å»ºç´¢å¼•æ—¶å‡ºé”™: {e}")
            cls._inverted_index = {}
            cls._code_to_fund = {}
    
    @classmethod
    def search_fund(cls, keyword: str, limit: int = 10) -> List[Dict]:
        """
        æœç´¢åŸºé‡‘ï¼ˆæ”¯æŒä»£ç ã€åç§°ã€æ‹¼éŸ³æ¨¡ç³ŠåŒ¹é…ï¼‰
        """
        if not keyword or len(keyword) < 2:
            return []
        
        keyword = str(keyword).strip()
        keyword_lower = keyword.lower()
        keyword_upper = keyword.upper()
        
        # ç¡®ä¿ç´¢å¼•å·²æ„å»º
        if cls._inverted_index is None or cls._code_to_fund is None:
            df = cls.get_fund_list()
            if cls._inverted_index is None:
                # å¦‚æœç´¢å¼•ä»ç„¶æœªæ„å»ºï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
                return cls._search_fund_fallback(df, keyword, limit)
        
        # ä½¿ç”¨å€’æ’ç´¢å¼•æœç´¢
        matched_codes = set()
        
        # 1. ç²¾ç¡®ä»£ç åŒ¹é…ï¼ˆå¦‚æœæ˜¯æ•°å­—ï¼‰
        if keyword.isdigit():
            if keyword in cls._code_to_fund:
                matched_codes.add(keyword)
        
        # 2. å‰ç¼€åŒ¹é…
        if keyword_lower in cls._inverted_index:
            matched_codes.update(cls._inverted_index[keyword_lower])
        if keyword_upper in cls._inverted_index:
            matched_codes.update(cls._inverted_index[keyword_upper])
        
        # 3. å­ä¸²åŒ¹é…ï¼ˆé’ˆå¯¹åç§°ï¼‰
        if len(keyword) > 2:
            for key in list(cls._inverted_index.keys()):
                if keyword_lower in key.lower():
                    matched_codes.update(cls._inverted_index[key])
                if len(matched_codes) >= limit * 2:  # æå‰ç»ˆæ­¢
                    break
        
        # 4. æ”¶é›†ç»“æœ
        results = []
        seen_codes = set()
        
        for code in matched_codes:
            if code in cls._code_to_fund and code not in seen_codes:
                results.append(cls._code_to_fund[code])
                seen_codes.add(code)
                if len(results) >= limit:
                    break
        
        # å¦‚æœç»“æœä¸è¶³ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
        if len(results) < limit:
            df = cls.get_fund_list()
            fallback_results = cls._search_fund_fallback(df, keyword, limit - len(results))
            
            # æ·»åŠ æœªé‡å¤çš„ç»“æœ
            for fund in fallback_results:
                if fund['code'] not in seen_codes:
                    results.append(fund)
                    seen_codes.add(fund['code'])
                    if len(results) >= limit:
                        break
        
        return results
    
    @classmethod
    def _search_fund_fallback(cls, df: pd.DataFrame, keyword: str, limit: int) -> List[Dict]:
        """å¤‡é€‰æœç´¢æ–¹æ¡ˆï¼ˆä½¿ç”¨åˆ—ç´¢å¼•ï¼‰"""
        keyword_upper = keyword.upper()
        results = []
        seen_codes = set()
        
        # å¿«é€Ÿè¿‡æ»¤ï¼šåªå¤„ç†å¯èƒ½åŒ¹é…çš„è¡Œ
        try:
            # ä½¿ç”¨å‘é‡åŒ–æ“ä½œå¿«é€Ÿè¿‡æ»¤
            mask = (
                df[cls.COL_CODE].astype(str).str.contains(keyword, na=False, case=False, regex=False) |
                df[cls.COL_NAME].str.contains(keyword, na=False, case=False, regex=False) |
                df[cls.COL_PINYIN_ABBR].str.contains(keyword_upper, na=False, regex=False)
            )
            
            filtered_df = df[mask]
            
            for idx, row in filtered_df.iterrows():
                if len(results) >= limit:
                    break
                
                try:
                    code = str(row.iloc[0])  # ç¬¬0åˆ—ï¼šåŸºé‡‘ä»£ç 
                    if code in seen_codes:
                        continue
                    
                    name = str(row.iloc[2])  # ç¬¬2åˆ—ï¼šåŸºé‡‘ç®€ç§°
                    pinyin_abbr = str(row.iloc[1])  # ç¬¬1åˆ—ï¼šæ‹¼éŸ³ç¼©å†™
                    fund_type = str(row.iloc[3])  # ç¬¬3åˆ—ï¼šåŸºé‡‘ç±»å‹
                    
                    results.append({
                        'code': code,
                        'name': name,
                        'pinyin': pinyin_abbr,
                        'type': fund_type
                    })
                    seen_codes.add(code)
                except Exception as e:
                    logger.debug(f"å¤„ç†æœç´¢ç»“æœæ—¶å‡ºé”™: {e}")
                    continue
        except Exception as e:
            logger.error(f"å¤‡ç”¨æœç´¢æ–¹æ¡ˆå‡ºé”™: {e}")
            # æç«¯æƒ…å†µï¼šé€è¡Œå¤„ç†
            for idx, row in df.iterrows():
                if len(results) >= limit:
                    break
                
                try:
                    code = str(row.iloc[0])
                    if code in seen_codes:
                        continue
                    
                    name = str(row.iloc[2])
                    pinyin_abbr = str(row.iloc[1])
                    
                    if (keyword in code or 
                        keyword in name or
                        keyword_upper in pinyin_abbr):
                        fund_type = str(row.iloc[3])
                        results.append({
                            'code': code,
                            'name': name,
                            'pinyin': pinyin_abbr,
                            'type': fund_type
                        })
                        seen_codes.add(code)
                except Exception as e:
                    logger.debug(f"é€è¡Œå¤„ç†æ—¶å‡ºé”™: {e}")
                    continue
        
        return results
    
    @classmethod
    def get_fund_by_code(cls, fund_code: str) -> Optional[Dict]:
        """é€šè¿‡åŸºé‡‘ä»£ç ç²¾ç¡®æŸ¥è¯¢"""
        fund_code = str(fund_code).strip()
        
        # ä¼˜å…ˆä½¿ç”¨ä»£ç æ˜ å°„
        if cls._code_to_fund and fund_code in cls._code_to_fund:
            return cls._code_to_fund[fund_code]
        
        # å¤‡ç”¨æ–¹æ¡ˆ
        df = cls.get_fund_list()
        
        try:
            result = df[df[cls.COL_CODE].astype(str) == fund_code]
            
            if result.empty:
                return None
            
            row = result.iloc[0]
            return {
                'code': str(row[cls.COL_CODE]),
                'name': str(row.get(cls.COL_NAME, '')),
                'pinyin': str(row.get(cls.COL_PINYIN_ABBR, '')),
                'type': str(row.get(cls.COL_TYPE, ''))
            }
        except Exception as e:
            logger.error(f"\u83b7\u53d6\u57fa\u91d1\u4fe1\u606f\u5931\u8d25: {e}")
            # å¤‡é€‰æ–¹æ¡ˆ
            for idx, row in df.iterrows():
                try:
                    if str(row.iloc[0]) == fund_code:
                        return {
                            'code': str(row.iloc[0]),
                            'name': str(row.iloc[2]),
                            'pinyin': str(row.iloc[1]),
                            'type': str(row.iloc[3])
                        }
                except Exception as e:
                    logger.debug(f"é€è¡ŒæŸ¥è¯¢æ—¶å‡ºé”™: {e}")
                    continue
            return None


# ==========================================
# Flask API è·¯ç”±
# ==========================================

estimator = SmartFundEstimator()
fund_analyzer = FundAnalyzer()
ai_service = AIService()

@app.route('/api/search_fund', methods=['GET'])
@limiter.limit("60 per minute")
def search_fund():
    """
    åŸºé‡‘æœç´¢æ¥å£ï¼ˆæ”¯æŒä»£ç ã€åç§°ã€æ‹¼éŸ³æ¨¡ç³ŠåŒ¹é…ï¼‰
    è¯·æ±‚: GET /api/search_fund?keyword=ç™½é…’&limit=10
    å“åº”: {"results": [{"code": "...", "name": "...", "pinyin": "...", "type": "..."}]}
    """
    keyword = request.args.get('keyword', '').strip()
    limit = request.args.get('limit', 10, type=int)
    
    if not keyword:
        return jsonify({'error': 'ç¼ºå°‘keywordå‚æ•°'}), 400
    
    if len(keyword) < 2:
        return jsonify({'error': 'å…³é”®è¯è‡³å°‘2ä¸ªå­—ç¬¦'}), 400
    
    if limit < 1 or limit > 20:
        limit = 10
    
    try:
        results = FundSearchService.search_fund(keyword, limit)
        return jsonify({
            'success': True,
            'keyword': keyword,
            'results': results,
            'count': len(results)
        })
    except Exception as e:
        logger.error(f"æœç´¢åŸºé‡‘é”™è¯¯: {e}")
        return jsonify({'error': 'æœç´¢æœåŠ¡æš‚æ—¶ä¸å¯ç”¨'}), 503


@app.route('/api/fund_info/<fund_code>', methods=['GET'])
@limiter.limit("60 per minute")
def fund_info(fund_code):
    """
    è·å–åŸºé‡‘åŸºæœ¬ä¿¡æ¯
    è¯·æ±‚: GET /api/fund_info/110011
    å“åº”: {"code": "...", "name": "...", "pinyin": "...", "type": "..."}
    """
    code = sanitize_fund_code(fund_code)
    if not code:
        return jsonify({'error': 'æ— æ•ˆçš„åŸºé‡‘ä»£ç '}), 400
    
    try:
        result = FundSearchService.get_fund_by_code(code)
        if result:
            return jsonify({
                'success': True,
                'fund': result
            })
        else:
            return jsonify({'error': 'åŸºé‡‘æœªæ‰¾åˆ°'}), 404
    except Exception as e:
        logger.error(f"è·å–åŸºé‡‘ä¿¡æ¯é”™è¯¯: {e}")
        return jsonify({'error': 'æœåŠ¡æš‚æ—¶ä¸å¯ç”¨'}), 503


@app.route('/api/parse_funds', methods=['POST'])
@limiter.limit("10 per minute")  # é™åˆ¶AIè§£æé¢‘ç‡ï¼ˆæˆæœ¬è¾ƒé«˜ï¼‰
def parse_funds():
    """
    AIæ™ºèƒ½è§£æåŸºé‡‘ä¿¡æ¯
    è¯·æ±‚: {"text": "ç”¨æˆ·è¾“å…¥çš„è‡ªç„¶è¯­è¨€æ–‡æœ¬"}
    å“åº”: {"funds": [{"code": "...", "name": "...", "holding": ...}]}
    """
    try:
        data = request.get_json()
        if not data or 'text' not in data:
            return jsonify({'error': 'ç¼ºå°‘textå‚æ•°'}), 400
        
        text = data['text']
        if not text or len(text) > 3000:
            return jsonify({'error': 'æ–‡æœ¬ä¸ºç©ºæˆ–è¿‡é•¿'}), 400
        
        funds = ai_service.parse_funds_natural_language(text)
        
        return jsonify({
            'success': True,
            'funds': funds,
            'count': len(funds)
        })
        
    except ValueError as e:
        return jsonify({'error': str(e)}), 400
    except Exception as e:
        logger.error(f"è§£æåŸºé‡‘é”™è¯¯: {e}")
        return jsonify({'error': 'è§£ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨'}), 503


@app.route('/api/estimate', methods=['POST'])
@limiter.limit("30 per minute")
def estimate():
    """ä»…ä¼°å€¼æ¥å£"""
    data = request.get_json()
    funds = data.get('funds', [])
    
    # éªŒè¯è¾“å…¥
    is_valid, msg = validate_funds_data(funds)
    if not is_valid:
        return jsonify({'error': msg}), 400
    
    logger.info(f"\nå¼€å§‹ä¼°ç®— {len(funds)} åªåŸºé‡‘ [v6.0 ç²¾ç®€ç‰ˆ]")
    
    results = []
    for fund in funds:
        try:
            result = estimator.estimate_fund(
                fund['code'],
                fund.get('name', fund['code']),
                fund['holding']
            )
            if result:
                results.append(result)
            time.sleep(0.5)  # é™ä½è¯·æ±‚é¢‘ç‡
        except Exception as e:
            logger.error(f"å¤„ç†é”™è¯¯: {e}")
    
    if results:
        total_holding = sum(r['holding'] for r in results)
        total_profit = sum(r['profit'] for r in results)
        portfolio_change = total_profit / total_holding * 100 if total_holding > 0 else 0
        
        return jsonify({
            'results': results,
            'summary': {
                'total_holding': float(total_holding),
                'total_profit': float(round(total_profit, 2)),
                'portfolio_change': float(round(portfolio_change, 2))
            }
        })
    
    return jsonify({'results': [], 'summary': {}})


@app.route('/api/fund_analysis', methods=['POST'])
@limiter.limit("20 per minute")
def fund_analysis():
    """
    åŸºé‡‘åˆ†ææ¥å£ï¼šä¼°å€¼ + å›æ’¤ï¼ˆ90æ—¥é«˜ç‚¹ï¼‰
    ä¸åŒ…å«æŠ•èµ„å»ºè®®å’Œç½‘æ ¼ç­–ç•¥
    ä½¿ç”¨å¹¶è¡Œå¤„ç†æå‡æ€§èƒ½
    """
    data = request.get_json()
    funds = data.get('funds', [])
    
    # éªŒè¯è¾“å…¥
    is_valid, msg = validate_funds_data(funds)
    if not is_valid:
        return jsonify({'error': msg}), 400
    
    logger.info(f"\n{'#'*70}")
    logger.info(f"å¯åŠ¨åŸºé‡‘åˆ†æ - å…±{len(funds)}åªåŸºé‡‘ï¼ˆå¹¶è¡Œå¤„ç†ç‰ˆï¼‰")
    logger.info(f"{'#'*70}")
    
    results = []
    
    def analyze_single_fund(fund):
        try:
            result = fund_analyzer.analyze_fund(
                fund['code'],
                fund.get('name', fund['code']),
                float(fund.get('holding', 0))
            )
            return result
        except Exception as e:
            logger.error(f"åˆ†æåŸºé‡‘ {fund['code']} æ—¶å‡ºé”™: {e}")
            return None
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†ï¼Œæœ€å¤š5ä¸ªå¹¶å‘
    max_workers = min(5, len(funds))
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_fund = {executor.submit(analyze_single_fund, fund): fund for fund in funds}
        
        for future in as_completed(future_to_fund):
            result = future.result()
            if result:
                results.append(result)
    
    summary = {
        'total_funds': int(len(funds)),
        'analyzed_successfully': int(len(results)),
        'timestamp': str(datetime.now().isoformat())
    }
    
    return jsonify({
        'summary': summary,
        'detailed_results': results
    })


@app.route('/api/drawdown', methods=['POST'])
@limiter.limit("30 per minute")
def drawdown():
    """ä»…å›æ’¤åˆ†ææ¥å£ï¼ˆé»˜è®¤90æ—¥çª—å£ï¼‰"""
    data = request.get_json()
    funds = data.get('funds', [])
    rolling_days = int(data.get('rolling_days', 90))
    
    if rolling_days not in [30, 60, 90, 120, 250]:
        return jsonify({'error': 'ä¸æ”¯æŒçš„å›æ’¤çª—å£æœŸ'}), 400
    
    results = []
    for fund in funds:
        try:
            code = sanitize_fund_code(fund['code'])
            if not code:
                continue
                
            result = get_fund_drawdown(
                code,
                rolling_days=rolling_days,
                target_date=fund.get('target_date')
            )
            if result:
                # è½¬æ¢å›æ’¤ä¸ºè´Ÿæ•°è¡¨ç¤ºä¸‹è·Œ
                result['drawdown_pct'] = -float(result['drawdown_pct'])
                results.append(result)
        except Exception as e:
            logger.error(f"è·å–å›æ’¤æ•°æ®å¤±è´¥ {fund.get('code')}: {e}")
    
    return jsonify({
        'rolling_window': f"{rolling_days}æ—¥",
        'results': results,
        'count': int(len(results))
    })


@app.route('/api/health', methods=['GET'])
def health():
    return jsonify({
        'status': 'ok', 
        'version': '6.4 Compare-Edition', 
        'time': str(datetime.now().isoformat()),
        'modules': ['estimate', 'drawdown', 'fund_analysis', 'ai_parse', 'fund_search', 'nav_history', 'nav_history_batch'],
        'default_window': '90d',
        'ai_enabled': ai_provider.is_configured(),
        'ai_provider': ai_provider.get_info(),
        'note': 'æ”¯æŒæ‰‹åŠ¨è¾“å…¥ã€åŸºé‡‘æœç´¢ã€æœ¬åœ°ç¼“å­˜ã€å‡€å€¼èµ°åŠ¿å›¾è¡¨ã€æ‰¹é‡å¯¹æ¯”åˆ†æ'
    })


@app.route('/api/get_indices', methods=['GET'])
@limiter.limit('30 per minute')
def get_indices():
    """
    è·å–å®æ—¶æŒ‡æ•°æ¶¨è·Œå¹…
    """
    try:
        indices = []
        
        # è·å–æ‰€æœ‰æ”¯æŒçš„æŒ‡æ•°
        for index_name, code in estimator.index_codes.items():
            try:
                change = estimator.get_index_change(index_name)
                indices.append({
                    'name': index_name,
                    'code': code,
                    'change': float(round(change, 2))
                })
            except Exception as e:
                logger.error(f"è·å–{index_name}æ•°æ®å¤±è´¥: {e}")
                # ç»§ç»­å¤„ç†å…¶ä»–æŒ‡æ•°ï¼Œä¸è¿”å›æ¨¡æ‹Ÿæ•°æ®
                indices.append({
                    'name': index_name,
                    'code': code,
                    'change': None,
                    'error': str(e)
                })
        
        return jsonify({
            'success': True,
            'indices': indices,
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        })
        
    except Exception as e:
        logger.error(f"APIé”™è¯¯: {e}")
        return jsonify({'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'}), 500


@app.route('/api/get_nav_history', methods=['GET'])
@limiter.limit('30 per minute')
def get_nav_history():
    """
    è·å–åŸºé‡‘å†å²å‡€å€¼æ•°æ®
    GET: /api/get_nav_history?code=110011&days=90
    """
    try:
        fund_code = request.args.get('code', '')
        days = request.args.get('days', 90, type=int)
        
        if not fund_code:
            return jsonify({'error': 'ç¼ºå°‘åŸºé‡‘ä»£ç '}), 400
        
        fund_code = sanitize_fund_code(fund_code)
        if not fund_code:
            return jsonify({'error': 'åŸºé‡‘ä»£ç æ ¼å¼é”™è¯¯'}), 400
        
        if days not in [30, 60, 90, 180, 365]:
            days = 90
        
        try:
            df = ak.fund_open_fund_info_em(symbol=fund_code, indicator="å•ä½å‡€å€¼èµ°åŠ¿")
        except Exception as e:
            logger.error(f"è·å–å‡€å€¼æ•°æ®å¤±è´¥ {fund_code}: {e}")
            return jsonify({
                'success': False,
                'message': f'è·å–å‡€å€¼æ•°æ®å¤±è´¥: {str(e)}'
            })
        
        if df is None or df.empty:
            return jsonify({
                'success': False,
                'message': 'æ— æ³•è·å–åŸºé‡‘å‡€å€¼æ•°æ®'
            })
        
        df = df.iloc[:, :2].copy()
        df.columns = ['date', 'nav']
        df['date'] = pd.to_datetime(df['date'])
        df['nav'] = pd.to_numeric(df['nav'], errors='coerce')
        df = df.dropna().sort_values('date')
        
        recent_df = df.tail(days)
        
        dates = recent_df['date'].dt.strftime('%Y-%m-%d').tolist()
        navs = recent_df['nav'].round(4).tolist()
        
        if len(navs) > 0:
            max_nav = float(recent_df['nav'].max())
            min_nav = float(recent_df['nav'].min())
            current_nav = float(navs[-1])
            start_nav = float(navs[0])
            total_return = ((current_nav - start_nav) / start_nav * 100) if start_nav > 0 else 0
            
            max_date = recent_df[recent_df['nav'] == recent_df['nav'].max()]['date'].iloc[-1].strftime('%Y-%m-%d')
            min_date = recent_df[recent_df['nav'] == recent_df['nav'].min()]['date'].iloc[-1].strftime('%Y-%m-%d')
        else:
            max_nav = min_nav = current_nav = start_nav = total_return = 0
            max_date = min_date = ''
        
        return jsonify({
            'success': True,
            'fund_code': fund_code,
            'days': days,
            'data': {
                'dates': dates,
                'navs': navs
            },
            'statistics': {
                'max_nav': round(max_nav, 4),
                'max_date': max_date,
                'min_nav': round(min_nav, 4),
                'min_date': min_date,
                'current_nav': round(current_nav, 4),
                'total_return': round(total_return, 2),
                'data_points': len(navs)
            },
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        })
        
    except Exception as e:
        logger.error(f"APIé”™è¯¯: {e}")
        return jsonify({'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'}), 500


@app.route('/api/get_nav_history_batch', methods=['GET'])
@limiter.limit('20 per minute')
def get_nav_history_batch():
    """
    æ‰¹é‡è·å–å¤šåªåŸºé‡‘å†å²å‡€å€¼æ•°æ®ï¼ˆç”¨äºå¯¹æ¯”åˆ†æï¼‰
    GET: /api/get_nav_history_batch?codes=110011,110022,110033&days=90
    """
    try:
        codes_param = request.args.get('codes', '')
        days = request.args.get('days', 180, type=int)
        
        if not codes_param:
            return jsonify({'error': 'ç¼ºå°‘åŸºé‡‘ä»£ç '}), 400
        
        codes = [sanitize_fund_code(c.strip()) for c in codes_param.split(',') if c.strip()]
        codes = [c for c in codes if c]
        
        if not codes:
            return jsonify({'error': 'æ²¡æœ‰æœ‰æ•ˆçš„åŸºé‡‘ä»£ç '}), 400
        
        if len(codes) > 4:
            return jsonify({'error': 'æœ€å¤šæ”¯æŒ4åªåŸºé‡‘å¯¹æ¯”'}), 400
        
        if days not in [30, 90, 180, 365]:
            days = 180
        
        results = []
        
        def fetch_single_fund(fund_code):
            try:
                df = ak.fund_open_fund_info_em(symbol=fund_code, indicator="å•ä½å‡€å€¼èµ°åŠ¿")
                
                if df is None or df.empty:
                    return None
                
                df = df.iloc[:, :2].copy()
                df.columns = ['date', 'nav']
                df['date'] = pd.to_datetime(df['date'])
                df['nav'] = pd.to_numeric(df['nav'], errors='coerce')
                df = df.dropna().sort_values('date')
                
                recent_df = df.tail(days)
                
                dates = recent_df['date'].dt.strftime('%Y-%m-%d').tolist()
                navs = recent_df['nav'].round(4).tolist()
                
                if len(navs) > 0:
                    max_nav = float(recent_df['nav'].max())
                    min_nav = float(recent_df['nav'].min())
                    current_nav = float(navs[-1])
                    start_nav = float(navs[0])
                    total_return = ((current_nav - start_nav) / start_nav * 100) if start_nav > 0 else 0
                else:
                    max_nav = min_nav = current_nav = start_nav = total_return = 0
                
                return {
                    'code': fund_code,
                    'data': {
                        'dates': dates,
                        'navs': navs
                    },
                    'statistics': {
                        'max_nav': round(max_nav, 4),
                        'min_nav': round(min_nav, 4),
                        'current_nav': round(current_nav, 4),
                        'total_return': round(total_return, 2),
                        'data_points': len(navs)
                    }
                }
            except Exception as e:
                logger.error(f"è·å–åŸºé‡‘ {fund_code} å‡€å€¼æ•°æ®å¤±è´¥: {e}")
                return None
        
        with ThreadPoolExecutor(max_workers=min(4, len(codes))) as executor:
            future_to_code = {executor.submit(fetch_single_fund, code): code for code in codes}
            
            for future in as_completed(future_to_code):
                result = future.result()
                if result:
                    results.append(result)
        
        return jsonify({
            'success': True,
            'funds': results,
            'days': days,
            'count': len(results),
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        })
        
    except Exception as e:
        logger.error(f"æ‰¹é‡è·å–å‡€å€¼æ•°æ®APIé”™è¯¯: {e}")
        return jsonify({'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'}), 500


@app.route('/api/get_fund_detail', methods=['GET'])
@limiter.limit('10 per minute')
def get_fund_detail():
    """
    è·å–åŸºé‡‘è¯¦æƒ…ï¼ŒåŒ…æ‹¬å®æ—¶æŒä»“è‚¡ç¥¨æ¶¨è·Œå¹…å’ŒåŠ æƒè®¡ç®—
    GET: /api/get_fund_detail?code=110011
    """
    try:
        fund_code = request.args.get('code', '')
        if not fund_code:
            return jsonify({'error': 'ç¼ºå°‘åŸºé‡‘ä»£ç '}), 400
        
        fund_code = sanitize_fund_code(fund_code)
        if not fund_code:
            return jsonify({'error': 'åŸºé‡‘ä»£ç æ ¼å¼é”™è¯¯'}), 400
        
        # è·å–åŸºé‡‘æŒä»“æ•°æ®
        try:
            df = ak.fund_portfolio_hold_em(symbol=fund_code, date="2025")
            if df.empty:
                df = ak.fund_portfolio_hold_em(symbol=fund_code, date="2024")
            
            if df.empty:
                return jsonify({
                    'success': False,
                    'message': 'æ— æ³•è·å–åŸºé‡‘æŒä»“æ•°æ®'
                })
            
            # è·å–æœ€æ–°å­£åº¦æ•°æ®
            latest_q = sorted(df['å­£åº¦'].unique(), reverse=True)[0]
            data = df[df['å­£åº¦'] == latest_q].head(10)
            
            # å¤„ç†æŒä»“æ•°æ®
            holdings = []
            codes = []
            names = []
            total_ratio = 0
            
            for _, row in data.iterrows():
                code = str(row['è‚¡ç¥¨ä»£ç '])
                name = str(row['è‚¡ç¥¨åç§°'])
                ratio = float(row['å å‡€å€¼æ¯”ä¾‹'])
                
                holdings.append({
                    'code': code,
                    'name': name,
                    'ratio': ratio
                })
                codes.append(code)
                names.append(name)
                total_ratio += ratio
            
            # è·å–è‚¡ç¥¨å®æ—¶æ¶¨è·Œå¹…
            changes = estimator.get_stock_changes(codes, names)
            
            # è®¡ç®—åŠ æƒè´¡çŒ®
            for holding in holdings:
                holding['change'] = changes.get(holding['code'], 0)
                holding['contribution'] = holding['change'] * holding['ratio'] / 100
            
            # è®¡ç®—åŸºå‡†æŒ‡æ•°æ¶¨è·Œå¹…
            market, benchmark, est_position = estimator.detect_market_and_benchmark(data, "")
            bench_chg = estimator.get_index_change(benchmark)
            
            # è®¡ç®—å‰©ä½™éƒ¨åˆ†è´¡çŒ®
            remaining_ratio = max(0, est_position * 100 - total_ratio)
            remaining_contrib = bench_chg * (remaining_ratio / 100)
            
            # è®¡ç®—æ€»æ¶¨è·Œå¹…
            total_change = sum(h['contribution'] for h in holdings) + remaining_contrib
            
            return jsonify({
                'success': True,
                'fund_code': fund_code,
                'holdings': holdings,
                'total_ratio': float(round(total_ratio, 2)),
                'remaining_ratio': float(round(remaining_ratio, 2)),
                'benchmark': benchmark,
                'benchmark_change': float(round(bench_chg, 2)),
                'total_change': float(round(total_change, 2)),
                'calculation_method': 'åŠ æƒå¹³å‡: æŒä»“è‚¡ç¥¨æ¶¨è·Œå¹… Ã— å æ¯” + å‰©ä½™éƒ¨åˆ†ä½¿ç”¨åŸºå‡†æŒ‡æ•°æ¶¨è·Œå¹…',
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            })
            
        except Exception as e:
            logger.error(f"è·å–åŸºé‡‘è¯¦æƒ…å¤±è´¥: {e}")
            return jsonify({
                'success': False,
                'message': str(e)
            })
        
    except Exception as e:
        logger.error(f"APIé”™è¯¯: {e}")
        return jsonify({'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'}), 500


# å…¨å±€é”™è¯¯å¤„ç†
@app.errorhandler(404)
def not_found(error):
    return jsonify({'error': 'æ¥å£ä¸å­˜åœ¨'}), 404

@app.errorhandler(500)
def internal_error(error):
    logger.error(f"æœåŠ¡å™¨é”™è¯¯: {error}")
    return jsonify({'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'}), 500

@app.errorhandler(429)
def ratelimit_handler(error):
    return jsonify({'error': 'è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•'}), 429


if __name__ == '__main__':
    print("="*70)
    print("åŸºé‡‘ä¼°å€¼ä¸å›æ’¤ç³»ç»Ÿ v6.2 - æ‰‹åŠ¨è¾“å…¥ç‰ˆ")
    print("åŠŸèƒ½ï¼šä¼°å€¼æ˜¾ç¤º + æ»šåŠ¨å›æ’¤ + åŸºé‡‘æœç´¢ + æœ¬åœ°ç¼“å­˜")
    print("æ¥å£åˆ—è¡¨ï¼š")
    print("  - GET  /api/search_fund      åŸºé‡‘æœç´¢ï¼ˆæ”¯æŒä»£ç /åç§°/æ‹¼éŸ³ï¼‰")
    print("  - GET  /api/fund_info/<code> è·å–åŸºé‡‘åŸºæœ¬ä¿¡æ¯")
    print("  - POST /api/parse_funds      AIè§£æè‡ªç„¶è¯­è¨€")
    print("  - POST /api/fund_analysis    åŸºé‡‘åˆ†æï¼ˆä¼°å€¼+å›æ’¤ï¼‰")
    print("  - POST /api/estimate         ä»…ä¼°å€¼")
    print("  - POST /api/drawdown         ä»…å›æ’¤")
    print("  - GET  /api/health           å¥åº·æ£€æŸ¥")
    print("="*70)
    
    # ç”Ÿäº§ç¯å¢ƒè¯·è®¾ç½® debug=False
    app.run(debug=False, port=5000, host='0.0.0.0')
